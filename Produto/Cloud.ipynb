{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando as bibliotecas\n",
    "from kafka import KafkaConsumer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Pegando dados da AWS s3\n",
    "\n",
    "    \n",
    "# geração da nuvem de palavras em tempo real\n",
    "frases = ''\n",
    "for messagem in consumer:\n",
    "    texto = json.loads(messagem.value.decode('utf-8'))\n",
    "    frases = frases + texto['tweet']\n",
    "    clear_output()\n",
    "    wordcloud = WordCloud(max_font_size=100, width=1520,\n",
    "                          height=535).generate(frases)\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "    .master('local[*]')\\\n",
    "    .appName('wordcloud')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_tweets(df):\n",
    "    words = df \\\n",
    "        .select (f.explode(f.split(f.lower('_c0'), \" \")).alias('word')) \\\n",
    "        .withColumn('word', f.regexp_replace('word', r'http\\S+', '')) \\\n",
    "        .withColumn('word', f.regexp_replace('word', r'@\\w+', '')) \\\n",
    "        .withColumn('word', f.regexp_replace('word', 'rt', '')) \\\n",
    "        .na.replace('', None) \\\n",
    "        .na.drop()\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('portuguese')\n",
    "stops.append('futebol') \n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "while True: \n",
    "    try:\n",
    "        words = spark.read.csv('./csv', encoding='utf-8')\n",
    "        words = trata_tweets(words)\n",
    "        rows = words.collect()\n",
    "        all_words = ''\n",
    "        for row in rows:\n",
    "            all_words = all_words + ' ' + row['word']\n",
    "\n",
    "        wordcloud = WordCloud(stopwords=stops,\n",
    "                     background_color=\"black\",\n",
    "                     width=1920,\n",
    "                     height=1080,\n",
    "                     max_words=100).generate(all_words)\n",
    "        plt.cla()        \n",
    "        plt.axis('off')\n",
    "        plt.imshow(wordcloud)\n",
    "        display.display(plt.gcf())  \n",
    "        display.clear_output(wait=True) \n",
    "        time.sleep(5)\n",
    "    except KeyboardInterrupt:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74d4420b2a354ae1b86e20a8c16bd244ae16f0674472ed68f809866a83afb121"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
